{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import log_loss,precision_recall_fscore_support,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file='/home/nacim/PycharmProjects/quora_questionpair/deep_learning/experiments/biconv1dlstm/06M_05D__18h_18min_TOT_WTIW_VYES_DYES_False_with GRU_validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.450940401732\n",
      "7.67095910521\n",
      "0.65029062421\n"
     ]
    }
   ],
   "source": [
    "p = 0.9\n",
    "p1 = 1-p\n",
    "df = pd.read_csv(file)\n",
    "print(log_loss(df.true.values,df.pred.values))\n",
    "d = df.pred.copy()\n",
    "d[d>=0.5]=1 #d[d>=0.6]*p1\n",
    "d[d<0.5] =0# d[d<0.6]*p\n",
    "df['pred'] = np.array(d)\n",
    "print(log_loss(df.true.values,df.pred.values))\n",
    "print(precision_score(df.true.values,df.pred.values,[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508496712213\n"
     ]
    }
   ],
   "source": [
    "w = {0: 0.79264259946672244, 1: 1.3542843743719155}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('trial1_correction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "('wave1', 1000)\n",
      "('wave2', 1000)\n",
      "('wave3', 50)\n",
      "('Length of Data', 2050)\n",
      "Creating train data...\n",
      "Mean of train data :  0.00171749842652\n",
      "Train data shape  :  (600, 100)\n",
      "('X shape:', (600, 99))\n",
      "('y shape:', (600,))\n",
      "Creating test data...\n",
      "Mean of test data :  0.0171606472292\n",
      "Test data shape  :  (400, 100)\n",
      "('Shape X_train', (2958, 99))\n",
      "('Shape X_test', (400, 99))\n",
      "[-1.67346592 -1.65393105 -1.58460475 -1.56246851 -1.54025105 -1.53053205\n",
      " -1.5224513  -1.51869812 -1.50438994 -1.50314504 -1.49574714 -1.49138424\n",
      " -1.48988996 -1.486926   -1.48544298 -1.48497851 -1.47414825 -1.47367204\n",
      " -1.47096659 -1.46863906 -1.46045597 -1.4548343  -1.44701698 -1.44404113\n",
      " -1.44240365 -1.43972787 -1.43572021 -1.43033172 -1.42664805 -1.41629206\n",
      " -1.41434153 -1.41017057 -1.40352459 -1.39030371 -1.38966824 -1.38905355\n",
      " -1.37925332 -1.37769472 -1.37621089 -1.3727004  -1.36900623 -1.3683298\n",
      " -1.36367545 -1.36085907 -1.36003962 -1.35965704 -1.35498773 -1.338631\n",
      " -1.33117036 -1.3255694  -1.32550959 -1.30997002 -1.30983154 -1.30447148\n",
      " -1.28808894 -1.28681263 -1.28503303 -1.28472133 -1.2841344  -1.28212516\n",
      " -1.28098229 -1.28039404 -1.27608328 -1.27589578 -1.27214385 -1.27201077\n",
      " -1.27083336 -1.26822239 -1.26718369 -1.26678054 -1.25159343 -1.24854452\n",
      " -1.23597773 -1.23070505 -1.23046205 -1.22691074 -1.22170428 -1.22149472\n",
      " -1.2207599  -1.21961968 -1.21686398 -1.21081282 -1.20351056 -1.20179943\n",
      " -1.19685485 -1.19627272 -1.19536035 -1.1897222  -1.18788139 -1.18764644\n",
      " -1.18455314 -1.17884216 -1.17851622 -1.17543303 -1.17408455 -1.17291494\n",
      " -1.16858259 -1.16071025 -1.15763769 -1.1545752  -1.14485085 -1.1432031\n",
      " -1.1431824  -1.13867612 -1.1301176  -1.12727144 -1.11884568 -1.10948573\n",
      " -1.10719171 -1.10541306 -1.10379814 -1.10037473 -1.09558297 -1.09518643\n",
      " -1.09280109 -1.09224125 -1.08984569 -1.08082429 -1.07594814 -1.0673425\n",
      " -1.06719632 -1.06159406 -1.0536879  -1.04407829 -1.04307342 -1.03353907\n",
      " -1.02596555 -1.02503321 -1.02058983 -1.00784727 -1.00495491 -1.00371668\n",
      " -1.00323342 -0.99765317 -0.9943137  -0.98873548 -0.98312235 -0.98120844\n",
      " -0.96908102 -0.96629998 -0.962943   -0.96008646 -0.95966039 -0.95376611\n",
      " -0.95104559 -0.94736431 -0.93595022 -0.93081203 -0.92601668 -0.92438852\n",
      " -0.91371618 -0.91077126 -0.91031946 -0.89172591 -0.89030658 -0.88561155\n",
      " -0.87743794 -0.87598921 -0.87315166 -0.85619117 -0.8518039  -0.82430702\n",
      " -0.82380986 -0.82058142 -0.81437976 -0.8108922  -0.79862239 -0.79373614\n",
      " -0.79238966 -0.78857273 -0.78776396 -0.76510062 -0.75943905 -0.75710487\n",
      " -0.75161428 -0.72919703 -0.70841204 -0.69345964 -0.69287817 -0.6852706\n",
      " -0.67753936 -0.66689426 -0.66202601 -0.66193274 -0.65938687 -0.65754761\n",
      " -0.6554438  -0.63507264 -0.63360529 -0.63129897 -0.59946107 -0.59903771\n",
      " -0.5932855  -0.57932886 -0.57812357 -0.57641029 -0.57332052 -0.57177506\n",
      " -0.56754401 -0.56272624 -0.54289463 -0.52935313 -0.51644282 -0.48576175\n",
      " -0.48518761 -0.47418275 -0.47317493 -0.47251673 -0.46966839 -0.46948508\n",
      " -0.46387231 -0.45865723 -0.45536622 -0.45294931 -0.45052581 -0.43584177\n",
      " -0.41667112 -0.40758004 -0.3896189  -0.38876278 -0.38034689 -0.37643903\n",
      " -0.36532835 -0.36495638 -0.36417458 -0.35671751 -0.35554851 -0.33033377\n",
      " -0.32566685 -0.32204642 -0.31528057 -0.31222509 -0.30729676 -0.29553708\n",
      " -0.29066716 -0.2882748  -0.2766127  -0.27048821 -0.24403051 -0.24297978\n",
      " -0.24268548 -0.24153944 -0.23507728 -0.2300039  -0.22049132 -0.19594428\n",
      " -0.1921171  -0.17294779 -0.17219332 -0.13528279 -0.11716136 -0.11437202\n",
      " -0.11400349 -0.06603298 -0.06474855 -0.06171755 -0.05547583 -0.04981576\n",
      " -0.04670223 -0.04571486 -0.040877   -0.03381382 -0.03331269 -0.02001383\n",
      " -0.01732669  0.00171796  0.0027199   0.01204649  0.03800549  0.03947645\n",
      "  0.04331683  0.04705129  0.05222202  0.05223444  0.05951486  0.06090589\n",
      "  0.06642844  0.07071447  0.07231504  0.07237327  0.08852249  0.09176765\n",
      "  0.10867806  0.10883249  0.11832884  0.13283663  0.13540571  0.14737829\n",
      "  0.15190265  0.17068014  0.18515437  0.18737753  0.19081642  0.19604554\n",
      "  0.20283813  0.20912048  0.21297804  0.24230136  0.25611002  0.27006837\n",
      "  0.281924    0.28538052  0.29257755  0.29510382  0.30893325  0.31235639\n",
      "  0.33202672  0.35627387  0.36102527  0.36430217  0.36867541  0.37175246\n",
      "  0.37321974  0.37544617  0.3780597   0.37928148  0.38266923  0.39187954\n",
      "  0.40303286  0.41237148  0.4134631   0.42414751  0.42891723  0.4446191\n",
      "  0.44578345  0.4578156   0.45869066  0.46606884  0.46635863  0.48020205\n",
      "  0.50030965  0.50188036  0.5393208   0.54628212  0.54774071  0.56520303\n",
      "  0.56655059  0.56805927  0.5741982   0.57752787  0.57947996  0.58009572\n",
      "  0.58418432  0.58940239  0.60717596  0.61312799  0.62604138  0.63682416\n",
      "  0.63865572  0.64533299  0.65249519  0.65882451  0.6662874   0.66719189\n",
      "  0.67441852  0.67991727  0.70119895  0.70304977  0.70791187  0.70900804\n",
      "  0.71470648  0.72359758  0.72804284  0.73293224  0.74387212  0.7473071\n",
      "  0.74854997  0.75080443  0.75766482  0.7744537   0.77836674  0.79313024\n",
      "  0.79722232  0.79829302  0.79972474  0.80275187  0.80517246  0.80708204\n",
      "  0.81237673  0.81444774  0.8160892   0.81641985  0.82079596  0.82282836\n",
      "  0.83068196  0.83868964  0.847786    0.85019769  0.85407991  0.8594899\n",
      "  0.86764869  0.87401016  0.87426077  0.88798496  0.91600138  0.91641397\n",
      "  0.91762905  0.9208305   0.92483349  0.93268098  0.94455851  0.95095702\n",
      "  0.96486127  0.96905006  0.97877185  0.99603383  0.99672759  0.99887943\n",
      "  1.00078862  1.00108239  1.00133912  1.001783    1.0019243   1.00485048\n",
      "  1.00958426  1.01939733  1.01999514  1.0425758   1.04564322  1.04973259\n",
      "  1.05280079  1.06089353  1.06672555  1.07485182  1.07493442  1.07621768\n",
      "  1.07871738  1.08406733  1.08424447  1.09239722  1.09553024  1.09871694\n",
      "  1.11958591  1.12269944  1.12730975  1.13495288  1.14307263  1.14551375\n",
      "  1.14845899  1.15055374  1.15339249  1.15672233  1.16012872  1.17903205\n",
      "  1.18328037  1.19224163  1.19448807  1.19834883  1.20022259  1.20337461\n",
      "  1.20504528  1.21338403  1.21755321  1.21780197  1.21942732  1.21958358\n",
      "  1.22216251  1.22772037  1.23835814  1.24073182  1.24803628  1.24827763\n",
      "  1.25465228  1.25679748  1.25884146  1.26228662  1.27246382  1.28329303\n",
      "  1.28417699  1.28470911  1.28882856  1.28888375  1.28986552  1.29002312\n",
      "  1.29137969  1.29421991  1.29887991  1.30065423  1.30212992  1.30273832\n",
      "  1.30289909  1.31338743  1.31927213  1.31947889  1.31953792  1.32231035\n",
      "  1.33113003  1.33167628  1.33374697  1.33737977  1.3384602   1.33973515\n",
      "  1.34655404  1.34693045  1.34747765  1.34798785  1.35384268  1.35431793\n",
      "  1.35643474  1.35666931  1.3571945   1.35839209  1.36181318  1.38074144\n",
      "  1.38780551  1.38845459  1.39109271  1.39150205  1.39215405  1.40143822\n",
      "  1.41616705  1.4172954   1.42520114  1.42531334  1.42904836  1.43125896\n",
      "  1.43362775  1.43658993  1.43806613  1.43990884  1.45154023  1.45577207\n",
      "  1.46595201  1.4801979   1.48569122  1.50560099  1.50876783  1.50956198\n",
      "  1.51809688  1.5265746   1.5282122   1.52875952  1.53271452  1.57337366\n",
      "  1.58086406  1.60445484  1.60531784  1.61914812  1.70411531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nacim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:35: DeprecationWarning: This function is deprecated. Please call randint(0, 10 + 1) instead\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Inspired by example from\n",
    "https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent\n",
    "Uses the TensorFlow backend\n",
    "The basic idea is to detect anomalies in a time-series.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from numpy import arange, sin, pi, random\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Global hyper-parameters\n",
    "sequence_length = 100\n",
    "random_data_dup = 10  # each sample randomly duplicated between 0 and 9 times, see dropin function\n",
    "epochs = 1\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "def dropin(X, y):\n",
    "    \"\"\" The name suggests the inverse of dropout, i.e. adding more samples. See Data Augmentation section at\n",
    "    http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/\n",
    "    :param X: Each row is a training sequence\n",
    "    :param y: Tne target we train and will later predict\n",
    "    :return: new augmented X, y\n",
    "    \"\"\"\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    X_hat = []\n",
    "    y_hat = []\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0, np.random.random_integers(0, random_data_dup)):\n",
    "            X_hat.append(X[i, :])\n",
    "            y_hat.append(y[i])\n",
    "    return np.asarray(X_hat), np.asarray(y_hat)\n",
    "\n",
    "\n",
    "def gen_wave():\n",
    "    \"\"\" Generate a synthetic wave by adding up a few sine waves and some noise\n",
    "    :return: the final wave\n",
    "    \"\"\"\n",
    "    t = np.arange(0.0, 10.0, 0.01)\n",
    "    wave1 = sin(2 * 2 * pi * t)\n",
    "    noise = random.normal(0, 0.1, len(t))\n",
    "    wave1 = wave1 + noise\n",
    "    print(\"wave1\", len(wave1))\n",
    "    wave2 = sin(2 * pi * t)\n",
    "    print(\"wave2\", len(wave2))\n",
    "    t_rider = arange(0.0, 0.5, 0.01)\n",
    "    wave3 = sin(10 * pi * t_rider)\n",
    "    print(\"wave3\", len(wave3))\n",
    "    insert = int(round(0.8 * len(t)))\n",
    "    wave1 = list(wave1)\n",
    "    wave2 = list(wave2)\n",
    "    wave3 = list(wave3)\n",
    "    wave1[insert:insert + 50] = wave1[insert:insert + 50] + wave3\n",
    "    return wave1 + wave2\n",
    "\n",
    "\n",
    "def z_norm(result):\n",
    "    result_mean = result.mean()\n",
    "    result_std = result.std()\n",
    "    result -= result_mean\n",
    "    result /= result_std\n",
    "    return result, result_mean\n",
    "\n",
    "\n",
    "def get_split_prep_data(train_start, train_end,\n",
    "                          test_start, test_end):\n",
    "    data = gen_wave()\n",
    "    print(\"Length of Data\", len(data))\n",
    "\n",
    "    # train data\n",
    "    print \"Creating train data...\"\n",
    "\n",
    "    result = []\n",
    "    for index in range(train_start, train_end - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result)  # shape (samples, sequence_length)\n",
    "    result, result_mean = z_norm(result)\n",
    "\n",
    "    print \"Mean of train data : \", result_mean\n",
    "    print \"Train data shape  : \", result.shape\n",
    "\n",
    "    train = result[train_start:train_end, :]\n",
    "    np.random.shuffle(train)  # shuffles in-place\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_train, y_train = dropin(X_train, y_train)\n",
    "\n",
    "    # test data\n",
    "    print \"Creating test data...\"\n",
    "\n",
    "    result = []\n",
    "    for index in range(test_start, test_end - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result)  # shape (samples, sequence_length)\n",
    "    result, result_mean = z_norm(result)\n",
    "\n",
    "    print \"Mean of test data : \", result_mean\n",
    "    print \"Test data shape  : \", result.shape\n",
    "\n",
    "    X_test = result[:, :-1]\n",
    "    y_test = result[:, -1]\n",
    "\n",
    "    print(\"Shape X_train\", np.shape(X_train))\n",
    "    print(\"Shape X_test\", np.shape(X_test))\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    layers = {'input': 1, 'hidden1': 64, 'hidden2': 256, 'hidden3': 100, 'output': 1}\n",
    "\n",
    "    model.add(LSTM(\n",
    "            input_length=sequence_length - 1,\n",
    "            input_dim=layers['input'],\n",
    "            output_dim=layers['hidden1'],\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden2'],\n",
    "            return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden3'],\n",
    "            return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "            output_dim=layers['output']))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print \"Compilation Time : \", time.time() - start\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_network(model=None, data=None):\n",
    "    global_start_time = time.time()\n",
    "\n",
    "    if data is None:\n",
    "        print 'Loading data... '\n",
    "        # train on first 700 samples and test on next 300 samples (has anomaly)\n",
    "        X_train, y_train, X_test, y_test = get_split_prep_data(0, 700, 500, 1000)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = data\n",
    "    print np.unique(y_train)\n",
    "    return\n",
    "\n",
    "    print '\\nData Loaded. Compiling...\\n'\n",
    "\n",
    "    if model is None:\n",
    "        model = build_model()\n",
    "\n",
    "    try:\n",
    "        print(\"Training...\")\n",
    "        model.fit(\n",
    "                X_train, y_train,\n",
    "                batch_size=batch_size, nb_epoch=epochs, validation_split=0.05)\n",
    "        print(\"Predicting...\")\n",
    "        predicted = model.predict(X_test)\n",
    "        print(\"Reshaping predicted\")\n",
    "        predicted = np.reshape(predicted, (predicted.size,))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"prediction exception\")\n",
    "        print 'Training duration (s) : ', time.time() - global_start_time\n",
    "        return model, y_test, 0\n",
    "\n",
    "    try:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(311)\n",
    "        plt.title(\"Actual Test Signal w/Anomalies\")\n",
    "        plt.plot(y_test[:len(y_test)], 'b')\n",
    "        plt.subplot(312)\n",
    "        plt.title(\"Predicted Signal\")\n",
    "        plt.plot(predicted[:len(y_test)], 'g')\n",
    "        plt.subplot(313)\n",
    "        plt.title(\"Squared Error\")\n",
    "        mse = ((y_test - predicted) ** 2)\n",
    "        plt.plot(mse, 'r')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"plotting exception\")\n",
    "        print str(e)\n",
    "    print 'Training duration (s) : ', time.time() - global_start_time\n",
    "\n",
    "    return model, y_test, predicted\n",
    "\n",
    "\n",
    "run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
